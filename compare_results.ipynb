{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert4rec_output_fp = \"results/bert_baseline/test_results/test_output.csv\"\n",
    "srgnn_output_fp = \"results/srgnn_baseline/test_results/test_output.csv\"\n",
    "bert_tlab_output_fp = \"results/bert_tlab_2/test_results/test_output.csv\"\n",
    "tlab_srgnn_output_fp = \"results/bert_tlab_2/test_results/test_output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert4rec_df = pd.read_csv(bert4rec_output_fp)\n",
    "srgnn_df = pd.read_csv(srgnn_output_fp)\n",
    "bert_tlab_df = pd.read_csv(bert_tlab_output_fp)\n",
    "tlab_srgnn_df = pd.read_csv(tlab_srgnn_output_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert4rec_df['top_20'] = bert4rec_df['top_20'].apply(ast.literal_eval)\n",
    "srgnn_df['top_20'] = srgnn_df['top_20'].apply(ast.literal_eval)\n",
    "bert_tlab_df['top_20'] = bert_tlab_df['top_20'].apply(ast.literal_eval)\n",
    "tlab_srgnn_df['top_20'] = tlab_srgnn_df['top_20'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compareTopK(results1, results2, k):\n",
    "    res1_count = 0\n",
    "    res2_count = 0\n",
    "    both_count = 0\n",
    "    for i in range(len(results1)):\n",
    "        if results1['label'][i] in results1['top_20'][i][0:k]:\n",
    "            if results2['label'][i] in results2['top_20'][i][0:k]:\n",
    "                res2_count += 1\n",
    "                both_count += 1\n",
    "            res1_count += 1\n",
    "        elif results2['label'][i] in results2['top_20'][i][0:k]:\n",
    "            res2_count += 1\n",
    "\n",
    "    return res1_count, res2_count, both_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCoverages(c1, c2, c3, n):\n",
    "    p1 = c1 / n\n",
    "    p2 = c2 / n\n",
    "    p3 = c3 / n\n",
    "    p1or2 = p1 + p2 - p3\n",
    "    p1only = p1 - p3\n",
    "    p2only = p2 - p3\n",
    "\n",
    "    return p1, p2, p3, p1or2, p1only, p2only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareModels(model1, model2, k):\n",
    "    models = {'bert': bert4rec_df, 'srgnn': srgnn_df, 'tlab': bert_tlab_df, 'tlab_srgnn': tlab_srgnn_df}\n",
    "    model1_df = models[model1]\n",
    "    model2_df = models[model2]\n",
    "\n",
    "    m1_top, m2_top, both_top = compareTopK(model1_df, model2_df, k)\n",
    "    p1, p2, p3, p1or2, p1only, p2only = getCoverages(m1_top, m2_top, both_top, len(model1_df))\n",
    "\n",
    "    print(model1, 'has the correct recommendation in top-', k, ' : ', p1)\n",
    "    print(model2, 'has the correct recommendation in top-', k, ' : ', p2)\n",
    "    print(model1, ' and ', model2, ' both have the correct recommendation in top-', k, ' : ', p3)\n",
    "    print('combined coverage of correct recommendation in top-', k, ' : ', p1or2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert has the correct recommendation in top- 1  :  0.23702710254260967\n",
      "srgnn has the correct recommendation in top- 1  :  0.1968706342553786\n",
      "bert  and  srgnn  both have the correct recommendation in top- 1  :  0.10581167924001117\n",
      "combined coverage of correct recommendation in top- 1  :  0.3280860575579771\n",
      "20\n",
      "bert has the correct recommendation in top- 20  :  0.6307963118189438\n",
      "srgnn has the correct recommendation in top- 20  :  0.5237943559653534\n",
      "bert  and  srgnn  both have the correct recommendation in top- 20  :  0.4820732048058117\n",
      "combined coverage of correct recommendation in top- 20  :  0.6725174629784856\n"
     ]
    }
   ],
   "source": [
    "print(\"top-1\")\n",
    "compareModels('bert', 'srgnn', 1)\n",
    "\n",
    "print(\"top-20\")\n",
    "compareModels('bert', 'srgnn', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tlab has the correct recommendation in top- 1  :  0.3297680916457111\n",
      "srgnn has the correct recommendation in top- 1  :  0.1968706342553786\n",
      "tlab  and  srgnn  both have the correct recommendation in top- 1  :  0.1463704945515507\n",
      "combined coverage of correct recommendation in top- 1  :  0.3802682313495389\n",
      "20\n",
      "tlab has the correct recommendation in top- 20  :  0.6642358200614696\n",
      "srgnn has the correct recommendation in top- 20  :  0.5237943559653534\n",
      "tlab  and  srgnn  both have the correct recommendation in top- 20  :  0.4946018440905281\n",
      "combined coverage of correct recommendation in top- 20  :  0.6934283319362949\n"
     ]
    }
   ],
   "source": [
    "print(\"top-1\")\n",
    "compareModels('tlab', 'srgnn', 1)\n",
    "\n",
    "print(\"top-20\")\n",
    "compareModels('tlab', 'srgnn', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert has the correct recommendation in top- 1  :  0.23702710254260967\n",
      "tlab has the correct recommendation in top- 1  :  0.3297680916457111\n",
      "bert  and  tlab  both have the correct recommendation in top- 1  :  0.20293378038558257\n",
      "combined coverage of correct recommendation in top- 1  :  0.3638614138027381\n",
      "20\n",
      "bert has the correct recommendation in top- 20  :  0.6307963118189438\n",
      "tlab has the correct recommendation in top- 20  :  0.6642358200614696\n",
      "bert  and  tlab  both have the correct recommendation in top- 20  :  0.5966750488963397\n",
      "combined coverage of correct recommendation in top- 20  :  0.6983570829840737\n"
     ]
    }
   ],
   "source": [
    "print(\"top-1\")\n",
    "compareModels('bert', 'tlab', 1)\n",
    "\n",
    "print(\"top-20\")\n",
    "compareModels('bert', 'tlab', 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datamining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
